---
layout: post
title: "Bayesian Inference: Beta-Binomial Distribution"
author: Kelsey Moore
description: Tutorial of how to create a beta-binomial posterior distribution
image: 
---

## What is Bayesian Inference?

In traditional statistical analysis, we draw conclusions based solely on sample data. Unfortunately, this limits our ability to make definitive inference. For example, we make confidence intervals, saying that we are some percent "confident" that the population parameter is within the determined bounds - we cannot say that there is some "probability" that the population parameter is within those bounds. Bayesian inference allows us to speak of population parameters in terms of probability, saying, for example, that there is some percent chance that the population parameter is within the determined bounds.

## Components of Bayesian Inference

Performing Bayesian inference involves four distributions: the prior distribution of the desired parameter, the likelihood of the collected data given the parameters, the marginal likelihood of the data, and the posterior distribution. They relate to each other as follows:

```math
Posterior = \frac{Likelihood \times Prior}{MarginalLikelihood} \rightarrow \pi(\theta|y) = \frac{f(y|\theta)\pi(\theta)}{f(y)}
```
## Bayesian Inference with a Beta-Binomial Distribution

The beta distribution is a conjugate prior for $\theta$ when the binomial likelihood is assumed. This means that a binomial likelihood for y | $\theta$ coupled with a beta prior distribution for $\theta$ produces a beta posterior distribution for $\theta$ | y.

## Example

Let's consider an example where we are interested in the proportion of people who consider themselves to be "morning people." We create a prior distribution of $\theta$~Beta(a=3,b=7), suggesting that 30% of people are morning people. The distribution would look like this:

![Figure](https://raw.githubusercontent.com/kbmoore02/my386blog/main/assets/images/prior.jpg)

After we collected 30 samples, 13 people identified themselves as morning people (successes) and 17 people did not (failures). Creating the posterior distribution for beta-binomial is very simple. It follows this formula: Beta(a* = a + succeses, b* = b + failures). So for this example, the posterior distribution is Beta(16, 24):

![Figure](https://raw.githubusercontent.com/kbmoore02/my386blog/main/assets/images/posterior.jpg)

Now that we've created our posterior distribution, we can draw inferences on the true population proportion of morning people. Using R, we can compute a credible interval. 

```math
qbeta(c(0.025,0.975), 16, 24)
```

There is a 95% probability that the true proportion of morning-people amongst all people is between 0.26 and 0.55. 

## Eliciting a Prior Distribution

One of the most challenging parts of Bayesian inference is determining what the prior distribution can be. Since we are trying to determine parameters of the population, it would seem that we have to pull the prior disribution out of thin air. However, in most cases, we have at least some prior knolwedge of the parameter we are interested in. 
